{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMoJIE.ipynb","provenance":[],"authorship_tag":"ABX9TyMNl9FuJPyYvFZ/gzPdfVKB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0sDedlkiM5FB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1595250920714,"user_tz":-60,"elapsed":8232,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"97cafdb3-dbb8-4c2f-baa5-8f9670c38e11"},"source":["!git clone https://github.com/dair-iitd/imojie"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'imojie'...\n","remote: Enumerating objects: 1863, done.\u001b[K\n","remote: Counting objects: 100% (1863/1863), done.\u001b[K\n","remote: Compressing objects: 100% (1513/1513), done.\u001b[K\n","remote: Total 1863 (delta 342), reused 1820 (delta 306), pack-reused 0\u001b[K\n","Receiving objects: 100% (1863/1863), 10.50 MiB | 24.05 MiB/s, done.\n","Resolving deltas: 100% (342/342), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LvA4HMzxNJR8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595250920722,"user_tz":-60,"elapsed":8076,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"a572c671-ab01-490a-e9b3-5861734495e6"},"source":["%cd imojie/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/imojie\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QRu2QT9pNbHB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595251222289,"user_tz":-60,"elapsed":309529,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"122c6d06-c815-44c0-cfe6-ad68a35da417"},"source":["pip install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Processing ./allennlp\n","Processing ./pytorch_transformers\n","Collecting conllu==1.3.1\n","  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n","Collecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n","\u001b[?25hCollecting Unidecode==1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 8.4MB/s \n","\u001b[?25hCollecting torch==1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 16kB/s \n","\u001b[?25hCollecting Flask_Cors==3.0.8\n","  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n","Collecting responses==0.10.9\n","  Downloading https://files.pythonhosted.org/packages/3e/0c/940781dd49710f4b1f0650c450c9fd8491db0e1bffd99ebc36355607f96d/responses-0.10.9-py2.py3-none-any.whl\n","Collecting jsonpickle==1.2\n","  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n","Collecting boto3==1.10.45\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/01/1c749dc1bca8dda969f5fe0ba16fa6d24c6bd96572d118f790773c54a636/boto3-1.10.45-py2.py3-none-any.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 39.5MB/s \n","\u001b[?25hCollecting overrides==2.7.0\n","  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n","Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.5.3)\n","Collecting ipdb==0.12.3\n","  Downloading https://files.pythonhosted.org/packages/5c/01/27427b1f4a97455b345297a48761544bc8e7fb1f3aef6904ec86ddf75f65/ipdb-0.12.3.tar.gz\n","Collecting gevent==1.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 40.1MB/s \n","\u001b[?25hCollecting word2number==1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Collecting matplotlib==3.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/11/06958a2b895a3853206dea1fb2a5b11bf044f626f90745987612af9c8f2c/matplotlib-3.1.2-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n","\u001b[K     |████████████████████████████████| 13.1MB 232kB/s \n","\u001b[?25hCollecting ftfy==5.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n","\u001b[?25hCollecting numpydoc==0.9.2\n","  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n","Collecting botocore==1.13.45\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/22/9f8201d900956e57a9811e1b1c91c9f76c87487c76f636c2df1ce8379c38/botocore-1.13.45-py2.py3-none-any.whl (5.9MB)\n","\u001b[K     |████████████████████████████████| 5.9MB 31.8MB/s \n","\u001b[?25hCollecting Flask==1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n","\u001b[K     |████████████████████████████████| 102kB 472kB/s \n","\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (2.10.0)\n","Collecting six==1.13.0\n","  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n","Collecting Sphinx==2.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/bb/64c45dd915150952feda858a112a13dc43fb24df2f397d82cdbd4db274b6/Sphinx-2.3.1-py3-none-any.whl (2.7MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 34.2MB/s \n","\u001b[?25hCollecting parsimonious==0.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 23)) (1.4.1)\n","Collecting thinqpbo==0.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/c9/9e7ff201047c98ec870e982c42565acec45bb5512424107ec64def8ff08c/thinqpbo-0.1.3.tar.gz (110kB)\n","\u001b[K     |████████████████████████████████| 112kB 41.3MB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 29.4MB/s \n","\u001b[?25hCollecting jsonnet==0.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n","\u001b[K     |████████████████████████████████| 256kB 38.9MB/s \n","\u001b[?25hCollecting sqlparse==0.3.0\n","  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\n","Collecting sentencepiece==0.1.85\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 27.8MB/s \n","\u001b[?25hCollecting pytest==5.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/cf/711f1d887cb92c5155c9a1eb338f1b5d2411b50e4492a3b20e4a188a22b2/pytest-5.3.2-py3-none-any.whl (234kB)\n","\u001b[K     |████████████████████████████████| 235kB 28.6MB/s \n","\u001b[?25hCollecting spacy==2.1.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n","\u001b[K     |████████████████████████████████| 30.9MB 91kB/s \n","\u001b[?25hCollecting numpy==1.17.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n","\u001b[K     |████████████████████████████████| 20.0MB 1.5MB/s \n","\u001b[?25hCollecting flaky==3.6.1\n","  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n","Requirement already satisfied: regex==2019.12.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (2019.12.20)\n","Collecting pytorch_pretrained_bert==0.6.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 41.6MB/s \n","\u001b[?25hRequirement already satisfied: docopt==0.6.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 35)) (0.6.2)\n","Collecting ipython==7.10.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/c0/dc2e62d068f0f63910a3ab565a7fbbe1a20946b23f0945525826d9bbc98f/ipython-7.10.2-py3-none-any.whl (778kB)\n","\u001b[K     |████████████████████████████████| 788kB 34.2MB/s \n","\u001b[?25hCollecting rouge==0.3.2\n","  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n","Collecting scikit_learn==0.22\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.0MB 32.7MB/s \n","\u001b[?25hCollecting sphinx_rtd_theme==0.4.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4MB)\n","\u001b[K     |████████████████████████████████| 6.4MB 34.9MB/s \n","\u001b[?25hCollecting tensorboardX==1.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n","\u001b[K     |████████████████████████████████| 194kB 45.3MB/s \n","\u001b[?25hCollecting transformers==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 41.2MB/s \n","\u001b[?25hCollecting easy_rouge==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/0c/0a/b7ebb887dac3ece27fffc65bbc7dc0abcf991f2ccce8073126329ce4be8f/easy_rouge-0.2.2-py3-none-any.whl\n","Collecting zenodo_get==1.3.0\n","  Downloading https://files.pythonhosted.org/packages/09/cc/72d8986d494148cbb9fe0f3000c38de863a52fb664599456f14e5d347878/zenodo_get-1.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.0-unreleased->-r requirements.txt (line 44)) (4.41.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.0-unreleased->-r requirements.txt (line 44)) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 2)) (2020.6.20)\n","Collecting idna<2.9,>=2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3==1.10.45->-r requirements.txt (line 8)) (0.10.0)\n","Collecting s3transfer<0.3.0,>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb==0.12.3->-r requirements.txt (line 11)) (49.1.0)\n","Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/a4/0d8685c98986326534b0753a8b92b3082bc9df42b348bc50d6c69839c9f9/greenlet-0.4.16-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 14)) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 14)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 14)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 14)) (2.4.7)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy==5.6->-r requirements.txt (line 15)) (0.2.5)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc==0.9.2->-r requirements.txt (line 16)) (2.11.2)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore==1.13.45->-r requirements.txt (line 17)) (0.15.2)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 18)) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 18)) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 18)) (1.0.1)\n","Collecting sphinxcontrib-serializinghtml\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/ca/bfad79b79b3821d0c6361c431f0ef4aec16ee248338b2c2013008b34d345/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl (89kB)\n","\u001b[K     |████████████████████████████████| 92kB 10.3MB/s \n","\u001b[?25hCollecting sphinxcontrib-htmlhelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 10.7MB/s \n","\u001b[?25hRequirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (2.8.0)\n","Collecting sphinxcontrib-qthelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 8.7MB/s \n","\u001b[?25hCollecting sphinxcontrib-jsmath\n","  Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (2.0.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (1.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (20.4)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (0.7.12)\n","Collecting sphinxcontrib-applehelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121kB)\n","\u001b[K     |████████████████████████████████| 122kB 37.1MB/s \n","\u001b[?25hCollecting sphinxcontrib-devhelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from Sphinx==2.3.1->-r requirements.txt (line 21)) (2.1.3)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.3.2->-r requirements.txt (line 29)) (1.9.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.3.2->-r requirements.txt (line 29)) (8.4.0)\n","Collecting pluggy<1.0,>=0.12\n","  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest==5.3.2->-r requirements.txt (line 29)) (1.7.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.3.2->-r requirements.txt (line 29)) (19.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.9->-r requirements.txt (line 30)) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.9->-r requirements.txt (line 30)) (0.7.0)\n","Collecting preshed<2.1.0,>=2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.9->-r requirements.txt (line 30)) (2.0.3)\n","Collecting thinc<7.1.0,>=7.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 42.5MB/s \n","\u001b[?25hCollecting blis<0.3.0,>=0.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 35.0MB/s \n","\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.9->-r requirements.txt (line 30)) (1.0.2)\n","Collecting plac<1.0.0,>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (4.3.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (0.7.5)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (0.17.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (0.2.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/a7/81b39aa50e9284fe2cb21cc7fb7de7817b224172d42793fd57451d38842b/prompt_toolkit-3.0.5-py3-none-any.whl (351kB)\n","\u001b[K     |████████████████████████████████| 358kB 40.3MB/s \n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.10.2->-r requirements.txt (line 36)) (4.4.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn==0.22->-r requirements.txt (line 38)) (0.16.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.9->-r requirements.txt (line 40)) (3.12.2)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 34.5MB/s \n","\u001b[?25hCollecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc==0.9.2->-r requirements.txt (line 16)) (1.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==5.3.2->-r requirements.txt (line 29)) (3.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.10.2->-r requirements.txt (line 36)) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython==7.10.2->-r requirements.txt (line 36)) (0.2.0)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.10.2->-r requirements.txt (line 36)) (0.7.0)\n","Building wheels for collected packages: overrides, ipdb, word2number, ftfy, numpydoc, parsimonious, thinqpbo, nltk, jsonnet, allennlp, pytorch-transformers, sacremoses, wget\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=5b78a12bd5e4ded6a3276d650c5859a93c77d20ef5943dfd6570a16c0e942584\n","  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.12.3-cp36-none-any.whl size=9225 sha256=c4b08ac2939a739334f38b98ecde741a3532edb73a6d94754f00e0c51642a9ad\n","  Stored in directory: /root/.cache/pip/wheels/57/43/c5/614153606de8f5e358e266723f53254e70752f4ffc8c85ec63\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=8494e970403d535d561b972ec7a6e8e0ee50bbd9c9a91ece73f540ecaaa63387\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44552 sha256=73f57d3c851714db24c3121ca66ad360fcc91bbb3e19d2e57ee4366ff81385be\n","  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31893 sha256=54b8490bb6c6d0b229111d6c4f653924fbf2f65b15ccca727add9c5e6bab5ab4\n","  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42712 sha256=363d5cfe1222479c78ec8bf37dfd51910d23ba124033fcf677a6fcd9a5c82428\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for thinqpbo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for thinqpbo: filename=thinqpbo-0.1.3-cp36-cp36m-linux_x86_64.whl size=393284 sha256=5809681c0c61b2c5eac7fe7ee5aaada910b267a62f46eca50dd8fd34056ae073\n","  Stored in directory: /root/.cache/pip/wheels/e4/ba/33/999840bf61d6410bd7dc9042e3b5cff4052af084737c9dd7c8\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449908 sha256=a3a0ee7d42550947b23e7b5b3b17608153415d646da6cf3677d4881d08c65625\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3319628 sha256=a903da560913f1ed5062c58a1a1fb3a2dbe416c20ac82cdb84a4489f39e981f8\n","  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n","  Building wheel for allennlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for allennlp: filename=allennlp-0.9.0_unreleased-cp36-none-any.whl size=7494024 sha256=636406526a579dd25a4220ccce83328c6a42df26fd98a7f32c6b26c25c1b992e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i44wowal/wheels/f5/af/6d/ed5d54b43a87d692a9a8086bce90ce89a844e05913422c8a16\n","  Building wheel for pytorch-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-transformers: filename=pytorch_transformers-1.0.0-cp36-none-any.whl size=153845 sha256=6418d87d5c08c9cb56f8eadb8df505ecdbc39466de2bc95ffc094eef838bb299\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i44wowal/wheels/7f/f8/0e/ef5ee0e5ce0af5a199e90cd0b351918276bd2ab489ce2eb59c\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=6eb2f35041e7b004dd5c103f2b28736139ba8d6da2088bee69a5f4ac6b4a0316\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=c60147da1101410e42b337c91b68629a81679eb82494e7ac155a40846915704e\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built overrides ipdb word2number ftfy numpydoc parsimonious thinqpbo nltk jsonnet allennlp pytorch-transformers sacremoses wget\n","\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.10.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: conllu, idna, requests, Unidecode, numpy, torch, six, Flask, Flask-Cors, responses, jsonpickle, botocore, s3transfer, boto3, overrides, prompt-toolkit, ipython, ipdb, greenlet, gevent, word2number, matplotlib, ftfy, sphinxcontrib-serializinghtml, sphinxcontrib-htmlhelp, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-applehelp, sphinxcontrib-devhelp, Sphinx, numpydoc, parsimonious, thinqpbo, nltk, jsonnet, sqlparse, sentencepiece, pluggy, pytest, preshed, plac, blis, thinc, spacy, flaky, pytorch-pretrained-bert, rouge, scikit-learn, sphinx-rtd-theme, tensorboardX, sacremoses, transformers, easy-rouge, wget, zenodo-get, allennlp, pytorch-transformers\n","  Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: torch 1.5.1+cu101\n","    Uninstalling torch-1.5.1+cu101:\n","      Successfully uninstalled torch-1.5.1+cu101\n","  Found existing installation: six 1.12.0\n","    Uninstalling six-1.12.0:\n","      Successfully uninstalled six-1.12.0\n","  Found existing installation: Flask 1.1.2\n","    Uninstalling Flask-1.1.2:\n","      Successfully uninstalled Flask-1.1.2\n","  Found existing installation: botocore 1.17.20\n","    Uninstalling botocore-1.17.20:\n","      Successfully uninstalled botocore-1.17.20\n","  Found existing installation: s3transfer 0.3.3\n","    Uninstalling s3transfer-0.3.3:\n","      Successfully uninstalled s3transfer-0.3.3\n","  Found existing installation: boto3 1.14.20\n","    Uninstalling boto3-1.14.20:\n","      Successfully uninstalled boto3-1.14.20\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: Sphinx 1.8.5\n","    Uninstalling Sphinx-1.8.5:\n","      Successfully uninstalled Sphinx-1.8.5\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: sqlparse 0.3.1\n","    Uninstalling sqlparse-0.3.1:\n","      Successfully uninstalled sqlparse-0.3.1\n","  Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Found existing installation: preshed 3.0.2\n","    Uninstalling preshed-3.0.2:\n","      Successfully uninstalled preshed-3.0.2\n","  Found existing installation: plac 1.1.3\n","    Uninstalling plac-1.1.3:\n","      Successfully uninstalled plac-1.1.3\n","  Found existing installation: blis 0.4.1\n","    Uninstalling blis-0.4.1:\n","      Successfully uninstalled blis-0.4.1\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed Flask-1.1.1 Flask-Cors-3.0.8 Sphinx-2.3.1 Unidecode-1.1.1 allennlp-0.9.0-unreleased blis-0.2.4 boto3-1.10.45 botocore-1.13.45 conllu-1.3.1 easy-rouge-0.2.2 flaky-3.6.1 ftfy-5.6 gevent-1.4.0 greenlet-0.4.16 idna-2.8 ipdb-0.12.3 ipython-7.10.2 jsonnet-0.14.0 jsonpickle-1.2 matplotlib-3.1.2 nltk-3.4.5 numpy-1.17.4 numpydoc-0.9.2 overrides-2.7.0 parsimonious-0.8.1 plac-0.9.6 pluggy-0.13.1 preshed-2.0.1 prompt-toolkit-3.0.5 pytest-5.3.2 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.0.0 requests-2.22.0 responses-0.10.9 rouge-0.3.2 s3transfer-0.2.1 sacremoses-0.0.43 scikit-learn-0.22 sentencepiece-0.1.85 six-1.13.0 spacy-2.1.9 sphinx-rtd-theme-0.4.3 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.4 sqlparse-0.3.0 tensorboardX-1.9 thinc-7.0.8 thinqpbo-0.1.3 torch-1.2.0 transformers-2.3.0 wget-3.2 word2number-1.1 zenodo-get-1.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","idna","matplotlib","mpl_toolkits","numpy","prompt_toolkit","requests","six","sphinxcontrib"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"x4mjlEUeYtJZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595251287980,"user_tz":-60,"elapsed":1086,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"ce70a583-0c52-4611-ed0d-c418857669dd"},"source":["%cd imojie/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/imojie\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mDPSRgb3NeHI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1595251339963,"user_tz":-60,"elapsed":42580,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"03d2b9fe-6670-4bfc-e693-0ea18a989f60"},"source":["!bash download_data.sh"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Title: IMoJIE Data\n","Keywords: Open Information Extraction\n","Publication date: 2020-05-01\n","DOI: 10.5281/zenodo.3775983\n","Total size: 68.8 MB\n","\n","Link: https://zenodo.org/api/files/82de25be-d47d-4a28-86cc-ac8004258fc9/imojie_data.tar.gz   size: 68.8 MB\n","\n","Checksum is correct. (fd685d16c6d2b4c8ce8f98c78435fbc4)\n","All files have been downloaded.\n","data/\n","data/train/\n","data/train/4cr_qpbo_extractions.tsv\n","data/train/4cr_comb_extractions.tsv.be\n","data/train/4cr_comb_extractions.tsv\n","data/train/4cr_comb_extractions.tsv.ba\n","data/train/oie4_extractions.tsv\n","data/test/\n","data/test/carb_sentences.txt\n","data/test/carb/\n","data/test/carb/extractions.tsv\n","data/test/carb/extractions.txt\n","data/vocab/\n","data/vocab/bert/\n","data/vocab/bert/non_padded_namespaces.txt\n","data/dev/\n","data/dev/carb_sentences.txt\n","data/dev/carb/\n","data/dev/carb/extractions.tsv\n","data/dev/carb/extractions.txt\n","data/.gitignore\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YcHnJIjbTyjb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1595251422930,"user_tz":-60,"elapsed":1298,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"36f96049-0461-4b5a-d179-b05260b3ad14"},"source":["import nltk\n","nltk.download('stopwords')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"OAUJY7FNPUBd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595252350174,"user_tz":-60,"elapsed":101793,"user":{"displayName":"Rayene Allouani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWzg1eZO0eQFuPfR1XnVu7HVnG0JLcJEA7EHJS7A=s64","userId":"11755433183739819335"}},"outputId":"f6095d08-1fb3-4451-e8aa-561d28894aeb"},"source":["!python allennlp_script.py --param_path imojie/configs/ba.json --s models/ba --mode train_test "],"execution_count":10,"outputs":[{"output_type":"stream","text":["{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","INFO:allennlp.common.params:random_seed = 13370\n","INFO:allennlp.common.params:numpy_seed = 1337\n","INFO:allennlp.common.params:pytorch_seed = 133\n","INFO:allennlp.common.checks:Pytorch version: 1.2.0\n","INFO:allennlp.common.params:evaluate_on_test = False\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'max_extractions': 10, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'lazy': True, 'target_namespace': 'bert', 'max_tokens': 500, 'bert': True, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq'} and extras set()\n","INFO:allennlp.common.params:dataset_reader.type = copy_seq2multiseq\n","INFO:allennlp.common.from_params:instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'max_extractions': 10, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'lazy': True, 'target_namespace': 'bert', 'max_tokens': 500, 'bert': True, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}} and extras set()\n","INFO:allennlp.common.params:dataset_reader.target_namespace = bert\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:dataset_reader.source_tokenizer.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()\n","INFO:allennlp.common.params:dataset_reader.source_tokenizer.model_name = bert-base-cased\n","INFO:allennlp.common.params:dataset_reader.source_tokenizer.do_lowercase = False\n","INFO:allennlp.common.params:dataset_reader.source_tokenizer.start_tokens = []\n","INFO:allennlp.common.params:dataset_reader.source_tokenizer.end_tokens = []\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:dataset_reader.target_tokenizer.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()\n","INFO:allennlp.common.params:dataset_reader.target_tokenizer.model_name = bert-base-cased\n","INFO:allennlp.common.params:dataset_reader.target_tokenizer.do_lowercase = False\n","INFO:allennlp.common.params:dataset_reader.target_tokenizer.start_tokens = []\n","INFO:allennlp.common.params:dataset_reader.target_tokenizer.end_tokens = []\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:dataset_reader.source_token_indexers.tokens.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()\n","INFO:allennlp.common.params:dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased\n","INFO:allennlp.common.params:dataset_reader.source_token_indexers.tokens.do_lowercase = False\n","INFO:allennlp.common.params:dataset_reader.source_token_indexers.tokens.namespace = bert\n","INFO:allennlp.common.params:dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.data.token_indexers.pretrained_transformer_indexer:Using token indexer padding value of 0\n","INFO:allennlp.common.params:dataset_reader.lazy = True\n","INFO:allennlp.common.params:dataset_reader.max_tokens = 500\n","INFO:allennlp.common.params:dataset_reader.bert = True\n","INFO:allennlp.common.params:dataset_reader.max_extractions = 10\n","INFO:allennlp.common.params:dataset_reader.dev_path = None\n","INFO:allennlp.common.params:dataset_reader.min_confidence = None\n","INFO:allennlp.common.params:dataset_reader.max_confidence = None\n","INFO:allennlp.common.params:dataset_reader.extraction_ratio = 1\n","INFO:allennlp.common.params:dataset_reader.validation = False\n","INFO:allennlp.common.params:dataset_reader.gradients = True\n","INFO:allennlp.common.params:dataset_reader.append_test = False\n","INFO:allennlp.common.params:dataset_reader.probability = False\n","INFO:allennlp.common.params:dataset_reader.order_sentences = \n","INFO:allennlp.training.util:Using a separate dataset reader to load validation and test data.\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'max_extractions': 10, 'validation': True, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'lazy': True, 'target_namespace': 'bert', 'max_tokens': 500, 'bert': True, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq'} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.type = copy_seq2multiseq\n","INFO:allennlp.common.from_params:instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'max_extractions': 10, 'validation': True, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'lazy': True, 'target_namespace': 'bert', 'max_tokens': 500, 'bert': True, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.target_namespace = bert\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.source_tokenizer.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.source_tokenizer.model_name = bert-base-cased\n","INFO:allennlp.common.params:validation_dataset_reader.source_tokenizer.do_lowercase = False\n","INFO:allennlp.common.params:validation_dataset_reader.source_tokenizer.start_tokens = []\n","INFO:allennlp.common.params:validation_dataset_reader.source_tokenizer.end_tokens = []\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.target_tokenizer.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.target_tokenizer.model_name = bert-base-cased\n","INFO:allennlp.common.params:validation_dataset_reader.target_tokenizer.do_lowercase = False\n","INFO:allennlp.common.params:validation_dataset_reader.target_tokenizer.start_tokens = []\n","INFO:allennlp.common.params:validation_dataset_reader.target_tokenizer.end_tokens = []\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.source_token_indexers.tokens.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()\n","INFO:allennlp.common.params:validation_dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased\n","INFO:allennlp.common.params:validation_dataset_reader.source_token_indexers.tokens.do_lowercase = False\n","INFO:allennlp.common.params:validation_dataset_reader.source_token_indexers.tokens.namespace = bert\n","INFO:allennlp.common.params:validation_dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","INFO:allennlp.data.token_indexers.pretrained_transformer_indexer:Using token indexer padding value of 0\n","INFO:allennlp.common.params:validation_dataset_reader.lazy = True\n","INFO:allennlp.common.params:validation_dataset_reader.max_tokens = 500\n","INFO:allennlp.common.params:validation_dataset_reader.bert = True\n","INFO:allennlp.common.params:validation_dataset_reader.max_extractions = 10\n","INFO:allennlp.common.params:validation_dataset_reader.dev_path = None\n","INFO:allennlp.common.params:validation_dataset_reader.min_confidence = None\n","INFO:allennlp.common.params:validation_dataset_reader.max_confidence = None\n","INFO:allennlp.common.params:validation_dataset_reader.extraction_ratio = 1\n","INFO:allennlp.common.params:validation_dataset_reader.validation = True\n","INFO:allennlp.common.params:validation_dataset_reader.gradients = True\n","INFO:allennlp.common.params:validation_dataset_reader.append_test = False\n","INFO:allennlp.common.params:validation_dataset_reader.probability = False\n","INFO:allennlp.common.params:validation_dataset_reader.order_sentences = \n","INFO:allennlp.common.params:train_data_path = data/train/oie4_extractions.tsv\n","INFO:allennlp.training.util:Reading training data from data/train/oie4_extractions.tsv\n","INFO:allennlp.common.params:validation_data_path = data/dev/carb_sentences.txt\n","INFO:allennlp.training.util:Reading validation data from data/dev/carb_sentences.txt\n","INFO:allennlp.common.params:test_data_path = None\n","INFO:allennlp.training.trainer_pieces:From dataset instances, validation, train will be considered for vocabulary creation.\n","INFO:allennlp.common.params:vocabulary.type = None\n","INFO:allennlp.common.params:vocabulary.extend = False\n","INFO:allennlp.common.params:vocabulary.directory_path = data/vocab/bert\n","INFO:allennlp.data.vocabulary:Loading Vocab from files instead of dataset.\n","INFO:allennlp.data.vocabulary:Loading token dictionary from data/vocab/bert.\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.model.Model'> from params {'beam_size': 5, 'max_extractions': 10, 'max_decoding_steps': 50, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_embedding_dim': 100, 'target_namespace': 'bert', 'bert': True, 'decoder_layers': 3, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'source_namespace': 'bert', 'append': True, 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'type': 'copy_seq2seq_bahdanu'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.type = copy_seq2seq_bahdanu\n","INFO:allennlp.common.from_params:instantiating class <class 'imojie.models.copy_seq2seq_bahdanu.CopyNetSeq2Seq'> from params {'beam_size': 5, 'max_extractions': 10, 'max_decoding_steps': 50, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_embedding_dim': 100, 'target_namespace': 'bert', 'bert': True, 'decoder_layers': 3, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'source_namespace': 'bert', 'append': True, 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}} and extras {'vocab'}\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","INFO:allennlp.common.params:model.source_embedder.type = basic\n","INFO:allennlp.common.params:model.source_embedder.embedder_to_indexer_map = None\n","INFO:allennlp.common.params:model.source_embedder.allow_unmatched_keys = False\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.source_embedder.token_embedders.tokens.type = pretrained_transformer\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True} and extras {'vocab'}\n","INFO:allennlp.common.params:model.source_embedder.token_embedders.tokens.model_name = bert-base-cased\n","INFO:allennlp.common.params:model.source_embedder.token_embedders.tokens.requires_grad = True\n","INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","INFO:pytorch_transformers.modeling_utils:Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.encoder.type = feedforward\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.feedforward_encoder.FeedForwardEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}} and extras {'vocab'}\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","INFO:allennlp.common.params:model.encoder.feedforward.input_dim = 768\n","INFO:allennlp.common.params:model.encoder.feedforward.num_layers = 1\n","INFO:allennlp.common.params:model.encoder.feedforward.hidden_dims = [256]\n","INFO:allennlp.common.params:model.encoder.feedforward.hidden_dims = [256]\n","INFO:allennlp.common.params:model.encoder.feedforward.activations = ['relu']\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu'] and extras {'vocab'}\n","INFO:allennlp.common.params:model.encoder.feedforward.activations = ['relu']\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n","INFO:allennlp.common.params:type = relu\n","INFO:allennlp.common.params:model.encoder.feedforward.dropout = 0.1\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.attention.type = linear\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.attention.linear_attention.LinearAttention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.attention.tensor_1_dim = 256\n","INFO:allennlp.common.params:model.attention.tensor_2_dim = 256\n","INFO:allennlp.common.params:model.attention.combination = x,y\n","INFO:allennlp.common.params:model.attention.activation = tanh\n","INFO:allennlp.common.registrable:instantiating registered subclass tanh of <class 'allennlp.nn.activations.Activation'>\n","INFO:allennlp.common.params:model.attention.normalize = True\n","INFO:allennlp.common.params:model.beam_size = 5\n","INFO:allennlp.common.params:model.max_decoding_steps = 50\n","INFO:allennlp.common.params:model.target_embedding_dim = 100\n","INFO:allennlp.common.params:model.decoder_layers = 3\n","INFO:allennlp.common.params:model.copy_token = @COPY@\n","INFO:allennlp.common.params:model.source_namespace = bert\n","INFO:allennlp.common.params:model.target_namespace = bert\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.training.metrics.metric.Metric'> from params {'dev_set': 'dev', 'type': 'carb'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.token_based_metric.type = carb\n","INFO:allennlp.common.from_params:instantiating class <class 'imojie.carb_metric.Carb'> from params {'dev_set': 'dev'} and extras {'vocab'}\n","INFO:allennlp.common.params:model.token_based_metric.dev_set = dev\n","INFO:allennlp.common.params:model.lambda_diversity = 5\n","INFO:allennlp.common.params:model.beam_search_type = beam_search\n","INFO:allennlp.common.params:model.bert = True\n","INFO:allennlp.common.params:model.append = True\n","INFO:allennlp.common.params:model.coverage = False\n","INFO:allennlp.common.params:model.max_extractions = 10\n","INFO:allennlp.common.params:model.decoder_config = \n","INFO:allennlp.common.params:model.decoder_type = lstm\n","INFO:allennlp.common.params:model.teacher_forcing = True\n","INFO:allennlp.nn.initializers:Initializing parameters\n","INFO:allennlp.nn.initializers:Done initializing parameters; the following parameters are using their default initialization from their code\n","INFO:allennlp.nn.initializers:   _attention._bias\n","INFO:allennlp.nn.initializers:   _attention._weight_vector\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_hh_l0\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_hh_l1\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_hh_l2\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_ih_l0\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_ih_l1\n","INFO:allennlp.nn.initializers:   _decoder_cell.bias_ih_l2\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_hh_l0\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_hh_l1\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_hh_l2\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_ih_l0\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_ih_l1\n","INFO:allennlp.nn.initializers:   _decoder_cell.weight_ih_l2\n","INFO:allennlp.nn.initializers:   _encoder._feedforward._linear_layers.0.bias\n","INFO:allennlp.nn.initializers:   _encoder._feedforward._linear_layers.0.weight\n","INFO:allennlp.nn.initializers:   _input_projection_layer.bias\n","INFO:allennlp.nn.initializers:   _input_projection_layer.weight\n","INFO:allennlp.nn.initializers:   _output_copying_layer.bias\n","INFO:allennlp.nn.initializers:   _output_copying_layer.weight\n","INFO:allennlp.nn.initializers:   _output_generation_layer.bias\n","INFO:allennlp.nn.initializers:   _output_generation_layer.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\n","INFO:allennlp.nn.initializers:   _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\n","INFO:allennlp.nn.initializers:   _target_embedder.weight\n","INFO:root:Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'biggest_batch_first': True, 'sorting_keys': [['target_tokens', 'num_fields'], ['source_tokens', 'num_tokens']], 'max_instances_in_memory': 10000, 'padding_noise': 0, 'batch_size': 32, 'maximum_samples_per_batch': ['num_tokens', 10000], 'type': 'bucket'} and extras set()\n","INFO:allennlp.common.params:iterator.type = bucket\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'biggest_batch_first': True, 'sorting_keys': [['target_tokens', 'num_fields'], ['source_tokens', 'num_tokens']], 'max_instances_in_memory': 10000, 'padding_noise': 0, 'batch_size': 32, 'maximum_samples_per_batch': ['num_tokens', 10000]} and extras set()\n","INFO:allennlp.common.params:iterator.sorting_keys = [['target_tokens', 'num_fields'], ['source_tokens', 'num_tokens']]\n","INFO:allennlp.common.params:iterator.padding_noise = 0\n","INFO:allennlp.common.params:iterator.biggest_batch_first = True\n","INFO:allennlp.common.params:iterator.batch_size = 32\n","INFO:allennlp.common.params:iterator.instances_per_epoch = None\n","INFO:allennlp.common.params:iterator.max_instances_in_memory = 10000\n","INFO:allennlp.common.params:iterator.cache_instances = False\n","INFO:allennlp.common.params:iterator.track_epoch = False\n","INFO:allennlp.common.params:iterator.maximum_samples_per_batch = ['num_tokens', 10000]\n","INFO:allennlp.common.params:iterator.skip_smaller_batches = False\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 128, 'sorting_keys': [['source_tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","INFO:allennlp.common.params:validation_iterator.type = bucket\n","INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 128, 'sorting_keys': [['source_tokens', 'num_tokens']]} and extras set()\n","INFO:allennlp.common.params:validation_iterator.sorting_keys = [['source_tokens', 'num_tokens']]\n","INFO:allennlp.common.params:validation_iterator.padding_noise = 0.1\n","INFO:allennlp.common.params:validation_iterator.biggest_batch_first = False\n","INFO:allennlp.common.params:validation_iterator.batch_size = 128\n","INFO:allennlp.common.params:validation_iterator.instances_per_epoch = None\n","INFO:allennlp.common.params:validation_iterator.max_instances_in_memory = None\n","INFO:allennlp.common.params:validation_iterator.cache_instances = False\n","INFO:allennlp.common.params:validation_iterator.track_epoch = False\n","INFO:allennlp.common.params:validation_iterator.maximum_samples_per_batch = None\n","INFO:allennlp.common.params:validation_iterator.skip_smaller_batches = False\n","INFO:allennlp.common.params:trainer.no_grad = ()\n","INFO:allennlp.training.trainer_pieces:Following parameters are Frozen  (without gradient):\n","INFO:allennlp.training.trainer_pieces:Following parameters are Tunable (with gradient):\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\n","INFO:allennlp.training.trainer_pieces:_source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\n","INFO:allennlp.training.trainer_pieces:_encoder._feedforward._linear_layers.0.weight\n","INFO:allennlp.training.trainer_pieces:_encoder._feedforward._linear_layers.0.bias\n","INFO:allennlp.training.trainer_pieces:_attention._weight_vector\n","INFO:allennlp.training.trainer_pieces:_attention._bias\n","INFO:allennlp.training.trainer_pieces:_target_embedder.weight\n","INFO:allennlp.training.trainer_pieces:_input_projection_layer.weight\n","INFO:allennlp.training.trainer_pieces:_input_projection_layer.bias\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_ih_l0\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_hh_l0\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_ih_l0\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_hh_l0\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_ih_l1\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_hh_l1\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_ih_l1\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_hh_l1\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_ih_l2\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.weight_hh_l2\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_ih_l2\n","INFO:allennlp.training.trainer_pieces:_decoder_cell.bias_hh_l2\n","INFO:allennlp.training.trainer_pieces:_output_generation_layer.weight\n","INFO:allennlp.training.trainer_pieces:_output_generation_layer.bias\n","INFO:allennlp.training.trainer_pieces:_output_copying_layer.weight\n","INFO:allennlp.training.trainer_pieces:_output_copying_layer.bias\n","INFO:allennlp.common.params:trainer.patience = None\n","INFO:allennlp.common.params:trainer.validation_metric = -loss\n","INFO:allennlp.common.params:trainer.shuffle = True\n","INFO:allennlp.common.params:trainer.num_epochs = 10\n","INFO:allennlp.common.params:trainer.cuda_device = 0\n","INFO:allennlp.common.params:trainer.grad_norm = None\n","INFO:allennlp.common.params:trainer.grad_clipping = None\n","INFO:allennlp.common.params:trainer.learning_rate_scheduler = None\n","INFO:allennlp.common.params:trainer.momentum_scheduler = None\n","INFO:allennlp.common.params:trainer.optimizer.type = bert_adam\n","INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n","INFO:allennlp.common.params:trainer.optimizer.parameter_groups.0.1.lr = 2e-05\n","INFO:allennlp.common.params:trainer.optimizer.parameter_groups.0.1.t_total = 50000\n","INFO:allennlp.common.params:trainer.optimizer.parameter_groups.0.1.warmup = 0.1\n","INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n","INFO:allennlp.common.params:trainer.optimizer.parameter_groups.1.1.lr = 0.001\n","INFO:allennlp.training.optimizers:Done constructing parameter groups.\n","INFO:allennlp.training.optimizers:Group 0: ['_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias'], {'lr': 2e-05, 't_total': 50000, 'warmup': 0.1}\n","INFO:allennlp.training.optimizers:Group 1: ['_target_embedder.weight', '_decoder_cell.weight_hh_l0', '_decoder_cell.bias_ih_l0', '_decoder_cell.weight_hh_l1', '_output_generation_layer.bias', '_output_copying_layer.weight', '_decoder_cell.bias_hh_l1', '_encoder._feedforward._linear_layers.0.weight', '_attention._weight_vector', '_input_projection_layer.bias', '_decoder_cell.weight_ih_l1', '_decoder_cell.weight_hh_l2', '_output_generation_layer.weight', '_decoder_cell.weight_ih_l0', '_output_copying_layer.bias', '_attention._bias', '_decoder_cell.bias_hh_l2', '_decoder_cell.bias_hh_l0', '_encoder._feedforward._linear_layers.0.bias', '_decoder_cell.bias_ih_l2', '_input_projection_layer.weight', '_decoder_cell.weight_ih_l2', '_decoder_cell.bias_ih_l1'], {'lr': 0.001}\n","INFO:allennlp.training.optimizers:Group 2: [], {}\n","INFO:allennlp.training.optimizers:Number of trainable parameters: 120660949\n","INFO:allennlp.common.params:trainer.optimizer.infer_type_and_cast = True\n","INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n","INFO:allennlp.common.params:trainer.optimizer.lr = 0.001\n","INFO:allennlp.common.registrable:instantiating registered subclass bert_adam of <class 'allennlp.training.optimizers.Optimizer'>\n","WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n","INFO:allennlp.common.params:trainer.num_serialized_models_to_keep = 2\n","INFO:allennlp.common.params:trainer.keep_serialized_model_every_num_seconds = None\n","INFO:allennlp.common.params:trainer.model_save_interval = None\n","INFO:allennlp.common.params:trainer.summary_interval = 100\n","INFO:allennlp.common.params:trainer.histogram_interval = None\n","INFO:allennlp.common.params:trainer.should_log_parameter_statistics = True\n","INFO:allennlp.common.params:trainer.should_log_learning_rate = False\n","INFO:allennlp.common.params:trainer.log_batch_size_period = None\n","WARNING:allennlp.training.trainer:You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n","INFO:allennlp.training.trainer:Beginning training.\n","INFO:allennlp.training.trainer:Epoch 0/9\n","INFO:allennlp.training.trainer:Peak CPU memory usage MB: 2995.068\n","INFO:allennlp.training.trainer:GPU 0 memory usage MB: 839\n","INFO:allennlp.training.trainer:Training\n","  0%|          | 0/1 [00:00<?, ?it/s]INFO:imojie.dataset_readers.copy_seq2multiseq:Reading instances from lines in file at: data/train/oie4_extractions.tsv\n","loss: 27.4162 ||: : 7it [01:08,  8.27s/it]Traceback (most recent call last):\n","  File \"allennlp_script.py\", line 151, in <module>\n","    main()\n","  File \"allennlp_script.py\", line 138, in main\n","    overrides=args.overrides\n","  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 168, in train_model_from_file\n","    cache_directory, cache_prefix)\n","  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 252, in train_model\n","    metrics = trainer.train()\n","  File \"/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\", line 478, in train\n","    train_metrics = self._train_epoch(epoch)\n","  File \"/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\", line 320, in _train_epoch\n","    loss = self.batch_loss(batch_group, for_training=True, optimizer=self.optimizer)\n","  File \"/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\", line 261, in batch_loss\n","    output_dict = self.model(**batch, optimizer=optimizer)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 547, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/imojie/imojie/models/copy_seq2seq_bahdanu.py\", line 389, in forward\n","    output_dict = self.forward_append(source_tokens, source_token_ids, source_to_target, metadata, target_tokens, target_token_ids, optimizer)\n","  File \"/content/imojie/imojie/models/copy_seq2seq_bahdanu.py\", line 288, in forward_append\n","    output_dict = self.train_append(source_tokens, source_token_ids, source_to_target, metadata, target_tokens, target_token_ids, optimizer=optimizer)\n","  File \"/content/imojie/imojie/models/copy_seq2seq_bahdanu.py\", line 514, in train_append\n","    loss_dict = self._forward_loss({'tokens': current_target}, current_target_token_ids, state)\n","  File \"/content/imojie/imojie/models/copy_seq2seq_bahdanu.py\", line 857, in _forward_loss\n","    copy_scores = self._get_copy_scores(state)\n","  File \"/content/imojie/imojie/models/copy_seq2seq_bahdanu.py\", line 722, in _get_copy_scores\n","    copy_projection = torch.tanh(copy_projection)\n","RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.74 GiB already allocated; 15.81 MiB free; 84.63 MiB cached)\n","\n","If you suspect this is an IPython bug, please report it at:\n","    https://github.com/ipython/ipython/issues\n","or send an email to the mailing list at ipython-dev@python.org\n","\n","You can print a more detailed traceback right now with \"%tb\", or use \"%debug\"\n","to interactively debug it.\n","\n","Extra-detailed tracebacks for bug-reporting purposes can be enabled via:\n","    %config Application.verbose_crash=True\n","\n","loss: 27.4162 ||: : 7it [01:28, 12.63s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qyi20njRbXFy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}